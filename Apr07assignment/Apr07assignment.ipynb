{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817ecaa4",
   "metadata": {},
   "source": [
    "# Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "## Polynomial functions and kernel functions are related in machine learning algorithms through the use of kernel trick. \n",
    "\n",
    "## Kernel functions are used to transform the input data into a higher dimensional space in order to make it easier to separate the data with a linear decision boundary. One common type of kernel function is the polynomial kernel, which is defined as:\n",
    "\n",
    "- ### K(x, y) = (x^T y + c)^d\n",
    "\n",
    "#### where x and y are input feature vectors, d is the degree of the polynomial, and c is a constant term.\n",
    "\n",
    "## On the other hand, a polynomial function is a function of the form:\n",
    "\n",
    "- ### f(x) = a_n x^n + a_{n-1} x^{n-1} + ... + a_1 x + a_0\n",
    "\n",
    "#### where a_i are constants and n is the degree of the polynomial.\n",
    "\n",
    "## In machine learning algorithms, we can use a polynomial kernel to implicitly transform the input data into a higher dimensional space, and this transformation can be seen as equivalent to using a polynomial function of a certain degree on the original input data. In this sense, the polynomial kernel is a way to generalize the concept of a polynomial function to the case where the input data may not be easily separable in the original feature space.\n",
    "\n",
    "### Therefore, the use of polynomial kernels in machine learning algorithms is related to the use of polynomial functions, as both involve raising the input data to a certain degree to transform it into a higher dimensional space. However, in the case of kernel functions, this transformation is done implicitly without actually computing the high-dimensional feature space, which can make the algorithm more efficient and scalable for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4f800a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a719daf5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082ccc51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5191f1f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "226506a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ef82e59",
   "metadata": {},
   "source": [
    "# Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077f1ae-fec7-4b18-8b5c-be83c1edbfa0",
   "metadata": {},
   "source": [
    "## To implement an SVM with a polynomial kernel in Python using Scikit-learn, we can use the `SVC` class and specify the kernel parameter as `'poly'`. Additionally, we can set the degree of the polynomial kernel using the `degree` parameter, and the coefficient of the polynomial kernel using the `coef0` parameter.\n",
    "\n",
    "### Here's an example code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181f0722-f2b6-435b-bbf1-2a7741781aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generating a random dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2,n_redundant=0, random_state=42)\n",
    "\n",
    "# Spliting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating an SVM model with a polynomial kernel of degree 3 and a coefficient of 1\n",
    "svm_poly = SVC(kernel='poly', degree=3, coef0=1)\n",
    "\n",
    "# Training the SVM model on the training data\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the accuracy of the SVM model on the testing data\n",
    "accuracy = svm_poly.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef23c5",
   "metadata": {},
   "source": [
    "### In this example, we first generate a random dataset using the `make_classification` function, and then split it into training and testing sets using the `train_test_split` function. We then create an SVM model with a polynomial kernel of degree 3 and a coefficient of 1 using the `SVC` class with the `kernel`, `degree`, and `coef0` parameters. Finally, we train the SVM model on the training data using the `fit` method and evaluate its accuracy on the testing data using the `score` method.\n",
    "\n",
    "## Note:\n",
    "- ### The choice of kernel and its parameters can greatly affect the performance of the SVM model, and may require tuning through cross-validation or other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509851b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73514ee5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f597c04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b23bfb18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "137cc3fb",
   "metadata": {},
   "source": [
    "# Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "## In Support Vector Regression (SVR), the parameter epsilon controls the width of the margin of tolerance around the regression line. Increasing the value of epsilon will allow more training samples to be within the margin of tolerance, resulting in a wider margin and potentially more support vectors.\n",
    "\n",
    "### As the margin becomes wider, the model becomes more tolerant of errors, and hence, the number of support vectors may increase. Conversely, reducing the value of epsilon will decrease the margin, making the model less tolerant of errors and potentially reducing the number of support vectors.\n",
    "\n",
    "### In summary, increasing the value of epsilon in SVR may increase the number of support vectors, but this will depend on the specific characteristics of the data and the value of other parameters such as the regularization parameter. It is important to note that the choice of epsilon should be made based on the specific problem at hand and through cross-validation or other methods to optimize the performance of the SVR model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864f44e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ccb400",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca3a9540",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e2b8830",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d37aadad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc846b69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "## In Support Vector Regression (SVR), the choice of kernel function and values of the C, epsilon, and gamma parameters can significantly affect the performance of the model. Here is an explanation of each parameter and how it affects the SVR model:\n",
    "\n",
    "- ## 1. Kernel function: The kernel function defines the mapping of the input data into a higher-dimensional feature space where a linear decision boundary can be used to separate the data. Popular kernel functions include linear, polynomial, and radial basis function (RBF) kernels. The choice of kernel function depends on the problem at hand and the characteristics of the data. For example, if the data has a nonlinear structure, a nonlinear kernel such as the polynomial or RBF kernel may be appropriate. \n",
    "\n",
    "- ## 2. C parameter: The C parameter controls the trade-off between model complexity and the margin of tolerance. A small value of C will result in a wider margin and more errors allowed in the training set, while a large value of C will result in a narrow margin and fewer errors allowed in the training set. A small value of C can be useful when the training data is noisy or when there are many outliers in the data, while a large value of C can be useful when the data is well-behaved and the model needs to fit the data more closely. \n",
    "\n",
    "- ## 3. Epsilon parameter: The epsilon parameter controls the width of the margin of tolerance around the regression line. It is used in epsilon-insensitive loss function, which ignores errors within a certain distance epsilon from the true value. A smaller value of epsilon will make the model more sensitive to errors and may lead to overfitting, while a larger value of epsilon will make the model more tolerant of errors and may lead to underfitting. \n",
    "\n",
    "- ## 4. Gamma parameter: The gamma parameter controls the shape of the kernel function and how it influences the decision boundary. A small value of gamma will result in a wide Gaussian kernel and a smooth decision boundary, while a large value of gamma will result in a narrow Gaussian kernel and a more complex decision boundary. A small value of gamma can be useful when the data is sparse or when the decision boundary is expected to be smooth, while a large value of gamma can be useful when the data is dense or when the decision boundary is expected to be more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085841c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceb61af9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3dbaa78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0a1e9a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87c3a7c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cad1459c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Q5. Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f4856",
   "metadata": {},
   "source": [
    "- ## Import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e215599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.264933Z",
     "iopub.status.busy": "2023-04-27T11:47:39.264531Z",
     "iopub.status.idle": "2023-04-27T11:47:39.556511Z",
     "shell.execute_reply": "2023-04-27T11:47:39.555417Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.264900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75adf984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.558644Z",
     "iopub.status.busy": "2023-04-27T11:47:39.558298Z",
     "iopub.status.idle": "2023-04-27T11:47:39.635597Z",
     "shell.execute_reply": "2023-04-27T11:47:39.634471Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.558610Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80705a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.637126Z",
     "iopub.status.busy": "2023-04-27T11:47:39.636820Z",
     "iopub.status.idle": "2023-04-27T11:47:39.652452Z",
     "shell.execute_reply": "2023-04-27T11:47:39.651310Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.637097Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1852b8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.655771Z",
     "iopub.status.busy": "2023-04-27T11:47:39.655421Z",
     "iopub.status.idle": "2023-04-27T11:47:39.661977Z",
     "shell.execute_reply": "2023-04-27T11:47:39.660761Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.655740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4078732d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.663642Z",
     "iopub.status.busy": "2023-04-27T11:47:39.663352Z",
     "iopub.status.idle": "2023-04-27T11:47:39.672516Z",
     "shell.execute_reply": "2023-04-27T11:47:39.671514Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.663613Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44372d57",
   "metadata": {},
   "source": [
    "- ## Split the dataset into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8fa3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.674023Z",
     "iopub.status.busy": "2023-04-27T11:47:39.673705Z",
     "iopub.status.idle": "2023-04-27T11:47:39.697062Z",
     "shell.execute_reply": "2023-04-27T11:47:39.695959Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.673993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.05,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e52361",
   "metadata": {},
   "source": [
    "- ## Pre-process the data using any technique of your choice (e.g. scaling, normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52208ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.698903Z",
     "iopub.status.busy": "2023-04-27T11:47:39.698497Z",
     "iopub.status.idle": "2023-04-27T11:47:39.704773Z",
     "shell.execute_reply": "2023-04-27T11:47:39.703504Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.698872Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15dbae1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.707910Z",
     "iopub.status.busy": "2023-04-27T11:47:39.707181Z",
     "iopub.status.idle": "2023-04-27T11:47:39.716007Z",
     "shell.execute_reply": "2023-04-27T11:47:39.715053Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.707864Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_traom = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80b1558d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.717932Z",
     "iopub.status.busy": "2023-04-27T11:47:39.717420Z",
     "iopub.status.idle": "2023-04-27T11:47:39.727924Z",
     "shell.execute_reply": "2023-04-27T11:47:39.726922Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.717888Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32417dd",
   "metadata": {},
   "source": [
    "- ## Create an instance of the SVC classifier and train it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac49e425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.732897Z",
     "iopub.status.busy": "2023-04-27T11:47:39.732562Z",
     "iopub.status.idle": "2023-04-27T11:47:39.825057Z",
     "shell.execute_reply": "2023-04-27T11:47:39.823813Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.732866Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e839b8f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.827438Z",
     "iopub.status.busy": "2023-04-27T11:47:39.826575Z",
     "iopub.status.idle": "2023-04-27T11:47:39.852044Z",
     "shell.execute_reply": "2023-04-27T11:47:39.851181Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.827401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffd595",
   "metadata": {},
   "source": [
    "- ## Use the trained classifier to predict the labels of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f0d2576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.853912Z",
     "iopub.status.busy": "2023-04-27T11:47:39.853125Z",
     "iopub.status.idle": "2023-04-27T11:47:39.859102Z",
     "shell.execute_reply": "2023-04-27T11:47:39.858014Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.853877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50c3ca",
   "metadata": {},
   "source": [
    "- ## Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "235dd154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.860619Z",
     "iopub.status.busy": "2023-04-27T11:47:39.860300Z",
     "iopub.status.idle": "2023-04-27T11:47:39.879975Z",
     "shell.execute_reply": "2023-04-27T11:47:39.878697Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.860589Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  9]\n",
      " [ 0 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.69      1.00      0.82        20\n",
      "\n",
      "    accuracy                           0.69        29\n",
      "   macro avg       0.34      0.50      0.41        29\n",
      "weighted avg       0.48      0.69      0.56        29\n",
      "\n",
      "0.6896551724137931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee292c3",
   "metadata": {},
   "source": [
    "- ## Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88b7549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.882335Z",
     "iopub.status.busy": "2023-04-27T11:47:39.881279Z",
     "iopub.status.idle": "2023-04-27T11:47:39.886279Z",
     "shell.execute_reply": "2023-04-27T11:47:39.885433Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.882300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a66717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.888697Z",
     "iopub.status.busy": "2023-04-27T11:47:39.888061Z",
     "iopub.status.idle": "2023-04-27T11:47:39.899187Z",
     "shell.execute_reply": "2023-04-27T11:47:39.898327Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.888646Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':['linear','rbf'],'C': [0.1, 1, 10, 100],'gamma': ['auto','scale']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68709c27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:47:39.901688Z",
     "iopub.status.busy": "2023-04-27T11:47:39.900925Z",
     "iopub.status.idle": "2023-04-27T11:50:13.758864Z",
     "shell.execute_reply": "2023-04-27T11:50:13.757696Z",
     "shell.execute_reply.started": "2023-04-27T11:47:39.901641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.935 total time=   0.1s\n",
      "[CV 2/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.981 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.880 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.926 total time=   0.1s\n",
      "[CV 5/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.972 total time=   0.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.935 total time=   0.1s\n",
      "[CV 2/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.981 total time=   0.1s\n",
      "[CV 3/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.880 total time=   0.1s\n",
      "[CV 4/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.926 total time=   0.1s\n",
      "[CV 5/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.972 total time=   0.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.889 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.898 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.907 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.963 total time=   0.5s\n",
      "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=0.991 total time=   1.0s\n",
      "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.917 total time=   0.3s\n",
      "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=0.963 total time=   0.7s\n",
      "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.981 total time=   0.9s\n",
      "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.963 total time=   0.5s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.991 total time=   1.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.917 total time=   0.3s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.963 total time=   0.7s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.981 total time=   0.9s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.935 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.926 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=auto, kernel=linear;, score=0.963 total time=   5.1s\n",
      "[CV 2/5] END ...C=10, gamma=auto, kernel=linear;, score=0.981 total time=   9.6s\n",
      "[CV 3/5] END ...C=10, gamma=auto, kernel=linear;, score=0.898 total time=   4.4s\n",
      "[CV 4/5] END ...C=10, gamma=auto, kernel=linear;, score=0.954 total time=   2.3s\n",
      "[CV 5/5] END ...C=10, gamma=auto, kernel=linear;, score=0.991 total time=   7.6s\n",
      "[CV 1/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.963 total time=   5.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.981 total time=   9.6s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.898 total time=   4.4s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.954 total time=   2.3s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.991 total time=   7.7s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.880 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.926 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=auto, kernel=linear;, score=0.954 total time=  17.2s\n",
      "[CV 2/5] END ..C=100, gamma=auto, kernel=linear;, score=0.991 total time=   5.4s\n",
      "[CV 3/5] END ..C=100, gamma=auto, kernel=linear;, score=0.907 total time=   3.4s\n",
      "[CV 4/5] END ..C=100, gamma=auto, kernel=linear;, score=0.944 total time=   5.8s\n",
      "[CV 5/5] END ..C=100, gamma=auto, kernel=linear;, score=0.981 total time=  10.6s\n",
      "[CV 1/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.954 total time=  17.0s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.991 total time=   5.5s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.907 total time=   3.4s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.944 total time=   5.8s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.981 total time=  10.6s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.954 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.907 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.935 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.954 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': ['auto', 'scale'],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = GridSearchCV(svc_model,param_grid=parameters,cv=5,scoring='accuracy',verbose=3)\n",
    "final_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a0d4104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:50:13.760905Z",
     "iopub.status.busy": "2023-04-27T11:50:13.760567Z",
     "iopub.status.idle": "2023-04-27T11:50:13.769429Z",
     "shell.execute_reply": "2023-04-27T11:50:13.768191Z",
     "shell.execute_reply.started": "2023-04-27T11:50:13.760873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 'auto', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95219531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:50:13.771614Z",
     "iopub.status.busy": "2023-04-27T11:50:13.771180Z",
     "iopub.status.idle": "2023-04-27T11:50:13.784503Z",
     "shell.execute_reply": "2023-04-27T11:50:13.783175Z",
     "shell.execute_reply.started": "2023-04-27T11:50:13.771571Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7586206896551724"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bd7e9",
   "metadata": {},
   "source": [
    "- ## Save the trained classifier to a file for future use.\n",
    "### Note: You can use any dataset of your choice for this assignment, but make sure it is suitable for classification and has a sufficient number of features and samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2596ed7f-bbc2-4366-bd1c-56477b1a56a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40d70e19-b095-45fd-b93a-633dbc2dc720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('breast_cancer_predictor.pkl','wb') as model:\n",
    "    pickle.dump(final_model,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
