{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9f68c27-a4c2-40ab-a465-9a4586bce349",
   "metadata": {},
   "source": [
    "> # Q1. What is the Filter method in feature selection, and how does it work?\n",
    "## Filter method is a feature selection technique that uses statistical techniques to evaluate the relationship between each input variable and the target variable. The scores obtained are used to choose (filter) those input variables that will be used in the model. The filter method ranks each feature based on some uni-variate metric and then selects the highest-ranking features. Some of the uni-variate metrics are variance: removing constant and quasi-constant features, correlation: removing highly correlated features, chi-squared: for categorical variables, ANOVA: for continuous variables, mutual information: for any type of variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f202805b-6baa-456c-8873-a119ee203ea4",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94036dbd-2bbe-41da-aac3-74ac19573685",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "359180b4-8bd8-4ecc-9a35-1219e7dcbbb7",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4f5989-4772-4531-b6e5-3ee5fab5d9a6",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c503c2c8",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e1cdf95-57c5-4c3a-afbf-5e9ac619ebbf",
   "metadata": {},
   "source": [
    "> # Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "## Wrapper method is a feature selection technique that uses a specific machine learning algorithm that we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion. Wrapper methods measure the importance of a feature based on its usefulness while training the Machine Learning model on it. On the other end, Filter methods select features based on some criteria like variance, correlation, etc. outside of the predictive models and subsequently model only the predictors that pass some criterion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30ef70fd-c9c7-471a-8c63-20fcf66b98c2",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15f0ad91-8196-4499-9e8f-d2415606c8d5",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc6585a0-de29-4a11-b313-75b8ac88f2b2",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a811c28-7e02-4fc6-ac78-ea012cea37d3",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23f8edaa",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6af3ef48-8d8a-4935-8176-36a800e080e4",
   "metadata": {},
   "source": [
    "> # Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "## Embedded methods are feature selection techniques that integrate the feature selection step as part of the learning process. Embedded methods combine the qualities of filter and wrapper methods. Some of the common techniques used in Embedded feature selection methods are Lasso Regression, Ridge Regression, Elastic Net, Decision Trees, Random Forest, Gradient Boosting, and Support Vector Machines."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6313b47-53e7-469c-9885-d306d00ec4a8",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ab9e52e-afa7-47e6-b874-32d8ea1f86da",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44e7267f-98d7-4db2-b6d6-7d6b1d2fa3c6",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "215ce7d9",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "540734e2-9f5e-4c1e-8fd2-19c1d9144de2",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca51aee8-c531-4ea5-baf6-cc867c921bb5",
   "metadata": {},
   "source": [
    "> # Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "## Filter methods look at individual features for identifying their relative importance. A feature may not be useful on its own but may be an important influencer when combined with other features. Filter methods may miss such features. Another drawback of filter methods is that they are not taking the relationship between feature variables or feature and target variables into account."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dfa4931-f982-4e46-b8ae-012cc5bc8be2",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9fb90e6-2884-458f-87f4-5c0adc09235e",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f39f1abd-f54c-4e5f-b1ae-57f706def290",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643756ed",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84cf5918-c217-4a7e-a734-d7c5c32d46bb",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60bf3473-465b-43c8-af75-2449f12c6d14",
   "metadata": {},
   "source": [
    "> # Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
    "## Filter methods are computationally less intensive than wrapper methods and are faster to implement. They are also less prone to overfitting than wrapper methods. Filter methods are useful when the number of features is large and the number of samples is small. They are also useful when the features are independent of each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8caa6aa-1d1a-493c-b90e-913d7477499d",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5238e8f8-b70b-45cf-bbd1-fd3e511adba0",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ca8e72e",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f31d56e4-83f7-4fd7-a383-207cb50f5397",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59ac62f1-c1ed-49d1-9334-68a7e9d200a6",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a1ff317-ec01-4e7d-ac05-cc48ab799dfe",
   "metadata": {},
   "source": [
    "> # Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "## To choose the most pertinent attributes for the model using the Filter Method, you can follow these steps:\n",
    "\n",
    "### 1.Calculate the correlation between each feature and the target variable (customer churn) using Pearson’s correlation coefficient or Spearman’s rank correlation coefficient.\n",
    "### 2.Select the features with the highest correlation coefficients.\n",
    "### 3.Remove any redundant features that are highly correlated with each other.\n",
    "### 4.Train the model using the selected features.\n",
    "## This method is computationally less intensive than wrapper methods and is faster to implement. It is also less prone to overfitting than wrapper methods. Filter methods are useful when the number of features is large and the number of samples is small. They are also useful when the features are independent of each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "412e8006-e386-4c36-b755-a8bf8ba06a55",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd546ccc",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59ea414-98be-4b16-a2bc-fb2182bf35a8",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6b89b4c-04d5-4917-91e3-6bf4875fbe18",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "449ae713-0449-485f-baa1-385ceaf425e5",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84802f8a-0f18-4468-bc94-160decf535b7",
   "metadata": {},
   "source": [
    "> # Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.\n",
    "## To select the most relevant features for the model using the Embedded method, you can follow these steps:\n",
    "\n",
    "### 1.Train a model using all the features.\n",
    "### 2.Calculate the feature importance scores using the model.\n",
    "### 3.Remove the features with the lowest importance scores.\n",
    "### 4.Train the model using the selected features.\n",
    "## The Embedded method is computationally more intensive than the Filter method but less intensive than the Wrapper method. It is useful when the number of features is large and the number of samples is small. It is also useful when the features are dependent on each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1c23cd1-b2b2-4c2d-a9f0-2e97f03d14b7",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b77a0bd8-85c5-4323-85a1-fcbebc34a41f",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "feebbaf0-2c0d-4f9c-829d-5267a57fa711",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40cc6550",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a205456-725d-4014-855f-b2cf09694171",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33a0d036-f3bc-409c-8d71-780d205a591c",
   "metadata": {
    "tags": []
   },
   "source": [
    "> # Q8. You are working on a project to predict the price of a house based on its features, such as size, location,and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor.\n",
    "## To select the best set of features for the predictor using the Wrapper method, you can follow these steps:\n",
    "\n",
    "### 1.Start with an empty set of features.\n",
    "### 2.Train a model using the current set of features and evaluate its performance using a validation set.\n",
    "### 3.Add a new feature to the set and train the model again.\n",
    "### 4.Evaluate the performance of the model using the validation set.\n",
    "### 5.If the performance improves, keep the new feature in the set and repeat steps 3-5.\n",
    "### 6.If the performance does not improve, remove the new feature from the set and repeat steps 3-5 with a different feature.\n",
    "### 7.Stop when the performance of the model no longer improves.\n",
    "## The Wrapper method is computationally more intensive than the Filter method but less intensive than the Embedded method. It is useful when the number of features is small and the number of samples is large. It is also useful when the features are dependent on each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
